apiVersion: v1
kind: Service
metadata:
  name: box
spec:
  ports:
  - name: http
    port: 8888
    protocol: TCP
    targetPort: 8888
  selector:
    component: pod
  clusterIP: None

---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: box
spec:
  # https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies
  # N.B. This is an attempt to ensure that when we update the statefulset we will kick the pod
  # even if there is only one pod.
  podManagementPolicy: Parallel
  replicas: 1
  revisionHistoryLimit: 10
  serviceName: box
  template:
    metadata:
      labels:    
        component: pod
    spec:
      securityContext:
      #   # 1000 = jupyter
      #   runAsUser: 1000
      #   runAsGroup: 100
      #   # Mount the PVC as a group that the user belongs to.
         fsGroup: 100
      containers:
      - env:
        - name: NB_USER
          value: jupyter
        # Set hugging face's cache directory to be on the PD. This is for permission reasons,
        # size reasons, as well as durability.        
        - name: TRANSFORMERS_CACHE
          value: /home/jupyter/.cache
        # Set the home directory explicitly to ensure it matches the PVC. Otherwise our home
        # directory won't be durable.
        - name: HOME
          value: /storage/jupyter
        image: tensorflow
        #image: ubuntu:20.04
        name: box
        # Explicitly set the command so we can use off the shelf notebook images.
        command:
        - /opt/startup.sh
        #  - tail
        #  - -f
        #  - /dev/null
        resources:
          limits:
            # nvidia.com/gpu: 0 # {"$kpt-set":"numGpus"}
            cpu: "8"
            memory: 16Gi
            ephemeral-storage:  10Gi
          requests:
            cpu: "4"
            memory: 4Gi
            ephemeral-storage:  10Gi
        securityContext:
          # 1000 = jupyter          
          runAsUser: 1000
          runAsGroup: 100        
        volumeMounts:
        - mountPath: /storage
          name: workspace
        - mountPath: /secrets
          name: ssh
        - mountPath: /authorized_keys
          name: auth-keys
      # TODO(jlewi): autopilot doesn't allow NET_ADMIN
      # Will this work without it
      - name: tailscale
        image: ghcr.io/tailscale/tailscale:latest
        env:
          # Store the state in a k8s secret
          # Can this be the same secret as TS_AUTH_KEY?
          - name: TS_KUBE_SECRET
            value: tailscale
          - name: TS_USERSPACE
            value: "true"
          - name: TS_AUTH_KEY
            valueFrom:
              secretKeyRef:
                name: tailscale-auth
                key: AUTH_KEY
                optional: true
        securityContext:
          runAsUser: 1000
          runAsGroup: 1000
      # We can't use NET_ADMIN when using Autopilot clusters
      #     capabilities:
      #       add:
      #       - NET_ADMIN
      serviceAccountName: dev
      volumes:
      - name: workspace
        persistentVolumeClaim:
          claimName: box
      - name: ssh
        # We use a projected volume: (https://kubernetes.io/docs/concepts/storage/projected-volumes/)
        # Because we want to combine multiple sources into a single directory
        # N.B. looks like secrets still get set with OWNER root
        # https://github.com/kubernetes/kubernetes/issues/81089
        # This means the .ssh directory won't be writable.
        projected:
          sources:
          - secret:
              name: jlewi-ssh
              items:
              - key: id_ed25519
                path: id_ed25519
                # See https://www.jannikarndt.de/blog/2018/03/ssh_key_as_kubernetes_secret/
                mode: 256
              - key: id_ed25519.pub
                path: id_ed25519.pub
      - name: auth-keys
        secret: 
          secretName: jlewi-auth-keys
      # - emptyDir:
      #     medium: Memory
      #   name: dshm
